{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1752067256222,
     "user": {
      "displayName": "Dagemawi Negash",
      "userId": "15489963942441824172"
     },
     "user_tz": -180
    },
    "id": "vaT_E3rMgIQ3",
    "outputId": "54057c33-9568-4ae1-eea9-bcb8f4fd3c3d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1752067258174,
     "user": {
      "displayName": "Dagemawi Negash",
      "userId": "15489963942441824172"
     },
     "user_tz": -180
    },
    "id": "tOP1Gcu1gsvo",
    "outputId": "e92a114b-16b6-4b13-f365-e372c5acc22d"
   },
   "outputs": [],
   "source": [
    "# Map digit to descriptive text prompt\n",
    "digit_to_text = {\n",
    "    0: \"a handwritten number zero\",\n",
    "    1: \"a handwritten number one\",\n",
    "    2: \"a handwritten number two\",\n",
    "    3: \"a handwritten number three\",\n",
    "    4: \"a handwritten number four\",\n",
    "    5: \"a handwritten number five\",\n",
    "    6: \"a handwritten number six\",\n",
    "    7: \"a handwritten number seven\",\n",
    "    8: \"a handwritten number eight\",\n",
    "    9: \"a handwritten number nine\"\n",
    "}\n",
    "\n",
    "class MNISTWithText(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        self.data = datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=train,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Pad(2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x * 2. - 1.)  # to make the data between [-1, 1] for stable training\n",
    "            ])\n",
    "        )\n",
    "        self.texts = [digit_to_text[int(label)] for label in self.data.targets]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        text = self.texts[idx]\n",
    "        return img, text, label\n",
    "\n",
    "train_dataset = MNISTWithText(train=True)\n",
    "test_dataset = MNISTWithText(train=False)\n",
    "\n",
    "# visualize some samples from the training set\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_samples = 6\n",
    "indices = np.random.choice(len(train_dataset), n_samples, replace=False)\n",
    "plt.figure(figsize=(12, 2))\n",
    "for i, idx in enumerate(indices):\n",
    "    img, text, label = train_dataset[idx]\n",
    "    plt.subplot(1, n_samples, i+1)\n",
    "    plt.imshow((img[0].numpy() + 1) / 2, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\\n{text}\", fontsize=9)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5CZHaxbhTEs"
   },
   "outputs": [],
   "source": [
    "# use a small BERT model for speed\n",
    "bert_model_name = \"prajjwal1/bert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert = AutoModel.from_pretrained(bert_model_name)\n",
    "bert = bert.to(device)\n",
    "\n",
    "# Freeze BERT weights for speed/memory\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def get_text_embedding(texts, device):\n",
    "    tokens = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=16)\n",
    "    input_ids = tokens['input_ids'].to(device)\n",
    "    attention_mask = tokens['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-4wq-1vhyyC"
   },
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "    timesteps: (batch,) or (1,)\n",
    "    Returns: (batch, embedding_dim)\n",
    "    \"\"\"\n",
    "    half_dim = embedding_dim // 2\n",
    "    exponent = torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) / half_dim\n",
    "    exponent = 10000 ** (-exponent)\n",
    "    emb = timesteps[:, None].float() * exponent[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjwakxvYkfwF"
   },
   "outputs": [],
   "source": [
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.q = nn.Conv2d(channels, channels, 1)\n",
    "        self.k = nn.Conv2d(channels, channels, 1)\n",
    "        self.v = nn.Conv2d(channels, channels, 1)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_norm = self.norm(x)\n",
    "        q = self.q(x_norm).reshape(B, C, H*W).permute(0, 2, 1)\n",
    "        k = self.k(x_norm).reshape(B, C, H*W)\n",
    "        v = self.v(x_norm).reshape(B, C, H*W).permute(0, 2, 1)\n",
    "        attn = torch.bmm(q, k) / (C ** 0.5)\n",
    "        attn = torch.softmax(attn, dim=-1)\n",
    "        out = torch.bmm(attn, v).permute(0, 2, 1).reshape(B, C, H, W)\n",
    "        out = self.proj(out)\n",
    "        return x + out\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, channels, context_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.q = nn.Conv2d(channels, channels, 1)\n",
    "        self.k = nn.Linear(context_dim, channels)\n",
    "        self.v = nn.Linear(context_dim, channels)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        B, C, H, W = x.shape\n",
    "        x_norm = self.norm(x)\n",
    "        q = self.q(x_norm).reshape(B, C, H*W).permute(0, 2, 1)\n",
    "        k = self.k(context).unsqueeze(1)\n",
    "        v = self.v(context).unsqueeze(1)\n",
    "        attn = torch.bmm(q, k.transpose(1, 2)) / (C ** 0.5)\n",
    "        attn = torch.softmax(attn, dim=1)\n",
    "        out = torch.bmm(attn, v).permute(0, 2, 1).reshape(B, C, H, W)\n",
    "        out = self.proj(out)\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4tNaRz-OJ9S"
   },
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, emb_dim, context_dim, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.emb_proj = nn.Linear(emb_dim, out_ch)\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.use_attn = use_attn\n",
    "        if use_attn:\n",
    "            self.attn = SelfAttention2d(out_ch)\n",
    "            self.cross_attn = CrossAttention(out_ch, context_dim)\n",
    "        self.down = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x, t_emb, context):\n",
    "        h = self.conv1(x)\n",
    "        h = self.norm1(h)\n",
    "        h = F.silu(h + self.emb_proj(t_emb)[:, :, None, None])\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        if self.use_attn:\n",
    "            h = self.attn(h)\n",
    "            h = self.cross_attn(h, context)\n",
    "        h_down = self.down(h)\n",
    "        return h_down, h\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, emb_dim, context_dim, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.emb_proj = nn.Linear(emb_dim, out_ch)\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.use_attn = use_attn\n",
    "        if use_attn:\n",
    "            self.attn = SelfAttention2d(out_ch)\n",
    "            self.cross_attn = CrossAttention(out_ch, context_dim)\n",
    "        self.up = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x, skip, t_emb, context):\n",
    "        def center_crop(tensor, target_height, target_width):\n",
    "            _, _, h, w = tensor.shape\n",
    "            start_h = (h - target_height) // 2\n",
    "            start_w = (w - target_width) // 2\n",
    "            return tensor[:, :, start_h:start_h+target_height, start_w:start_w+target_width]\n",
    "\n",
    "        if x.shape[2:] != skip.shape[2:]:\n",
    "            skip = center_crop(skip, x.shape[2], x.shape[3])\n",
    "        h = torch.cat([x, skip], dim=1)\n",
    "        h = self.conv1(h)\n",
    "        h = self.norm1(h)\n",
    "        h = F.silu(h + self.emb_proj(t_emb)[:, :, None, None])\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        if self.use_attn:\n",
    "            h = self.attn(h)\n",
    "            h = self.cross_attn(h, context)\n",
    "        h_up = self.up(h)\n",
    "        return h_up\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, img_ch=1, base_ch=64, emb_dim=128, context_dim=128):\n",
    "        super().__init__()\n",
    "        self.init_conv = nn.Conv2d(img_ch, base_ch, 3, padding=1)\n",
    "        self.down1 = DownBlock(base_ch, base_ch*2, emb_dim, context_dim, use_attn=False)\n",
    "        self.down2 = DownBlock(base_ch*2, base_ch*4, emb_dim, context_dim, use_attn=True)\n",
    "        self.down3 = DownBlock(base_ch*4, base_ch*8, emb_dim, context_dim, use_attn=True)\n",
    "        self.bot1 = nn.Conv2d(base_ch*8, base_ch*8, 3, padding=1)\n",
    "        self.bot2 = nn.Conv2d(base_ch*8, base_ch*8, 3, padding=1)\n",
    "        self.up3 = UpBlock(base_ch*8+base_ch*8, base_ch*4, emb_dim, context_dim, use_attn=True)\n",
    "        self.up2 = UpBlock(base_ch*4+base_ch*4, base_ch*2, emb_dim, context_dim, use_attn=True)\n",
    "        self.up1 = UpBlock(base_ch*2+base_ch*2, base_ch, emb_dim, context_dim, use_attn=False)\n",
    "        self.final_conv = nn.Conv2d(base_ch, img_ch, 1)\n",
    "\n",
    "    def forward(self, x, t_emb, context):\n",
    "        h0 = self.init_conv(x)\n",
    "        h1_down, h1 = self.down1(h0, t_emb, context)\n",
    "        h2_down, h2 = self.down2(h1_down, t_emb, context)\n",
    "        h3_down, h3 = self.down3(h2_down, t_emb, context)\n",
    "        h_bot = F.silu(self.bot1(h3_down))\n",
    "        h_bot = F.silu(self.bot2(h_bot))\n",
    "        h_up3 = self.up3(h_bot, h3, t_emb, context)\n",
    "        h_up2 = self.up2(h_up3, h2, t_emb, context)\n",
    "        h_up1 = self.up1(h_up2, h1, t_emb, context)\n",
    "        out = self.final_conv(h_up1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjf0ARVSOyeW"
   },
   "outputs": [],
   "source": [
    "def make_beta_schedule(n_steps, beta_start=1e-4, beta_end=0.02):\n",
    "    return torch.linspace(beta_start, beta_end, n_steps)\n",
    "\n",
    "T = 1000  # number of diffusion steps\n",
    "betas = make_beta_schedule(T)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4USxnNbMcPrx"
   },
   "outputs": [],
   "source": [
    "def classifier_free_guidance(model, x, t, context, null_context, guidance_scale):\n",
    "    eps_cond = model(x, t, context)\n",
    "    eps_uncond = model(x, t, null_context)\n",
    "    return eps_uncond + guidance_scale * (eps_cond - eps_uncond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f0859c929e77481b8561b8832df3e0a9",
      "90f629b5faed491c94508d9fac3bdafd",
      "d5befa1298404d49ad07f3a2791f0c84",
      "1cc5185b4c8c4c448b33e968534de8e7",
      "8a48fa15515f4c598083c38cc85850a6",
      "21174bd9a7394d78b01d9626a8e81501",
      "5cfbb0a031954a8bb4020f2a1832368f",
      "964825ecd8b14ab18083fe0c9f8ffd1b",
      "d08405c34d7b44cea79bbede8d2f6bbe",
      "c59bcb9f8d2f486db3cbebe8e9f3a27f",
      "98ced2a88a614f9d96eabafd3d27ffa4",
      "489b0fb415144063ba5fe268d946f892",
      "5d085e4cc01342c8a0dd187c8d8f8a7b",
      "2aafa2abea2d4443a44a400ffb2b90b2",
      "d93c2cb17d7b485f97f7eb6691f5c49d",
      "be608cf02ae440c08c32b313c356f14b",
      "670f99134d23467888a972a200357dc4",
      "98b635a613a74e979ae3f1579e0d0194",
      "55280b44a8f14fdbb9ddf5d4c22a3776",
      "4b1341512859483d86fb8ee869483df6",
      "fb303904be0b41f6ae48435b9732b8b4",
      "ae5634a8cb1c4752aa066a4f890c2e38",
      "84d1b71f14a64deab531bf12f2aff3b1",
      "2fdbf8438c364872a1bc634ffce7122d",
      "69d8deaa4418427bbd528c0d162c3f6c",
      "9048f8e16c034294a7005ec1c1cd2483",
      "e68a3738bc05469497474421962a0c32",
      "08a0fdb018d74b7d8950c44d11f5652d",
      "5de598eebcf146cf8d64f5500b46e5f4",
      "bf24f1c980ce42f8b1801ff49d4127b9",
      "4a17e30bba524574a231ed733c28f383",
      "a120dd30a7f74e4e8cb59fc4bb99357e",
      "30af8957e1b2477da87b172138ba9902",
      "ebe8b6b724924bb2aac93df51575a20c",
      "1edc3a5e6a1344228413e0bba772c9ef",
      "0a19614d72e54882966671edbcc0ed2f",
      "6dc1b420324e484ab4fc2cb3d1ad0400",
      "98c2b195f4a44d8da62d8a711c0f2cd9",
      "6415e4a3653a47f691869aa17740faea",
      "7f7bb25180cd411fb6c85c047131d19b",
      "4cf184eaa868417bbaaf142330f82a10",
      "ed4969eb1dab420e858818d3d893581f",
      "3cf1756a721e407a95c846979629cd84",
      "adad0bcd0f384d22965bcca8cc662bd1",
      "57d845933ca04b17a403f69ebc51efe2",
      "d388a54daab542e89c16989c3c96cb42",
      "0e30b13a5c9546d1b215bf70599ad296",
      "375eed6f30eb4b5c89eeea5d873f84c6",
      "e9aadd36c63c4ceeb658a27d9d8929da",
      "bc7b74dd017c4f6cad2e5a3a67c1a02c",
      "e4e6ade42d5e49b98253ecf3f3efd43c",
      "f4921ab265f94f57852f26b328b41233",
      "0ced83c9114f4c8e82a58a6e8f2ab2f3",
      "aa856589d5274fd6a495ea98d7c6a339",
      "0812d51c4e4f4ab38763f92bdb41318f",
      "df8535fd69014565869a1db4c27720a3",
      "5ec3ea8094d04eedbe38d14e938edfd8",
      "4e51f41ed2e942fea6d1cb0a1a9e8a07",
      "fd41e29aedc747d481ae96aaa00e2577",
      "51ed220a73284bd69872ed8317c6244a",
      "994870dd636043318bdfcc5d92e69a0b",
      "d435fa86d8a74922aca742a28a3a3d92",
      "f3a949c37e684e1bae4e4185e9f0deb0",
      "72b43397d5aa419b9189245143ed1fa0",
      "2425ba396cae450294660a30eed66f69",
      "eecd08b1b09c48a8b3f32893f389db2d",
      "c2e3ba78a06d4ff1b4916b74fda2f3f7",
      "4270b8ca8dd846d7a873d03bb9bfdc53",
      "8c14a97ffcc54416a49fed3fdce33c24",
      "cfd31513fccb43e4ace6a6d2affc9cf3",
      "55c94b2659e6440ea78d6ac810b3d760",
      "bd78c0cdc2fe459c9a9eea4052fcee0b",
      "4c2a866d073e4fea97f51cd7bc5a7781",
      "d2e60665718b43958ee3bf87d5cbe008",
      "4bd7b83405b74caaae92fd50d4ae6b22",
      "4a64859e97cf45ec93183b0f7a15b2c8",
      "746fc9af2a194a96838b9f49710b1e6e",
      "73c0adf5eded491ababf56ecb058e52e",
      "6efea8bd14d64fb4ada85968a56e83c6",
      "c811da82e84d416d93eac51eee867644",
      "2b5557d5596c4d23807838ddb141993c",
      "c22b062f0eff4c07bd0cb1a27b4da530",
      "94ecb83077f54f24a5ee7a01a6cb7333",
      "f39cb6032ec74f29a1bdef1e3dd320a4",
      "3c3065dae7c04aa8bee81f7f5b7bde71",
      "4fdf8204669a473982b2263977c12432",
      "26f7e71e4ff3436c8a88053f9f9364b0",
      "2622a6597028425bba2a68a1590d651d",
      "53d825d5b3784f87be8570971397fbc0",
      "2e26f8fb97ff466eb38301b982ec594e",
      "c27626c0c2944eae94dae5f5a66786b1",
      "052bdbb0518b49dc817c9c107294d2ba",
      "f78e17ca314a467ba3b0e1baa1bd3639",
      "5b5bb9e37d5e4eb0b8c52d4765b035a0",
      "750bed9f9ccb47d5bae2adbeecdc149c",
      "4dfd31187f8c4c41b85e78c07a814224",
      "bd0bca487b1247a481a9e185540144fc",
      "14f3a93466a844f3a7aee863507c207f",
      "f4b10bbe93a14158979e9929ba9eacf2",
      "db0b94728ab942f9a1a615c4e1dddf80",
      "38210888fd02447596cdd5e7cf0cedd2",
      "a47532d443644945965e681059d7f2c7",
      "4b168a24686844088e3ae02674e50e16",
      "f15d21f9457e491194d3121f3459beb8",
      "5372f381fa1d4e4e88d15ff60c8610e9",
      "549b055ede044dc59d4945a7491b5917",
      "e34ebd5f1e2147cda2a85fba26b71923",
      "0971ce9fa1194653871e68b138aeb871",
      "209937ae1c2e4a3dbfac9a57fe951e9d",
      "7e6515c9aa474571b69e94538e2a3a32",
      "a08d1412e1d24fe6b17cb5e9357d4084",
      "4b07aab6192b4eb082aafc9216c7878e",
      "99ecda9db896458a8b71ac2e1061a8ae",
      "dffd8f052db44b3a8fce984411d6df25",
      "9eb9e259aff041608b908f724eface6a",
      "2764d8a11c7f431180034d3d67de2331",
      "d80ee8b61f4c4df0a01a0dea0f1cd4d6",
      "700da6f0837d4752b56d6bcd773771c7",
      "2a8210bc8b8c415597656244acf6b5f0",
      "432373d207544129924fff71655729b0",
      "87a6f246e2a0478a9f7fbbc863050ea2",
      "78d63aa0e3ab44b7939c63172edefac1",
      "25a9b1ec14ca4ffa8dea0dc7042c37bc",
      "34e8f6b3590d4524bb638ca6c3c52438",
      "3fa93789d3c3459faab9a7bdf04a857e",
      "0401dbfd7ac24f1c93d8617941eed374",
      "94d1aa633305471cb657f31df8e4bd9b",
      "549c89546533421cbf8ef7eeb5589bb0",
      "9deb86b98f7840df88e51f123b794830",
      "2ebaba9fc5704ab3a91afb099a8dd126",
      "b859cc4217064e5c9c9f1ba2838b216f",
      "580d633cbc174847be3cb4b0b5db92ac",
      "6859b4ea2b6c40d69523ce5b44e0124e",
      "5f688f47ce074aa08fe1a57a87bfa13f",
      "69650b021c9e47bfb6d8c51525d229e1",
      "20cd126946124a149579602121d694ac",
      "568f61a8998646b286bab6bdd5df5b05",
      "341f4135ed7440a2820f5add503e805e",
      "9ca2c7a916e54aca9e3b9c0f7e8b194a",
      "97d38a33bbc94e6bb0399ef2197e4a68",
      "29efef2dd1924c41838d6d59687698dc",
      "6b6847c3f6224e679b6491e2be8dbf7c",
      "a7e6819c3f4f4d529b756a2a585be9ab",
      "9d64cad433304346b919fcb2865ecf65",
      "fa179f5703794ffa9d52eca0eb13472f",
      "53516830369f44f789bb73ffdb24fda7",
      "5036317f50734dd1b8d8c04f24b47827",
      "b06bc73af0b849a098ca168a9178af89",
      "a1a3fe71b77342b0951dfe2dc0364afa",
      "5e4ef181cbcb42009bf8f7cb9b8e630a",
      "e69407e4ac5140dd886013b47f6d2a17",
      "9ca204e83fd84251a34959c64936643e",
      "a183a1766bbc4f4fa6972c6dc9f19b19",
      "42d86e6522b243fd9513f39fd5575d22",
      "e85b80303130445f9011d8e5e2f948b9",
      "4ea7abea4e684b51b698b68ef8257727",
      "ca12d5f1a0464efa98a0efaa5eebc96d",
      "33b3e3b26d764c9db4253cb13e3f619e",
      "c639604cf97f4b6b8c31a61e92865dfd",
      "09581f444855473d8febbf50b9a03af1",
      "6dd07d77e58040c9ae612116e2caad0b",
      "25d5b44baffc4af7a859a9b61f8a03eb",
      "b81622ae25a746df8055452432b3a12f",
      "b04530db262945568f799672e04657c4",
      "e5be3aa05d8f48d9870648b660afa99e",
      "6f0e71f8dac24439b8a78d6c8723e8e8",
      "7446f96554694598a959593e0bcf672c",
      "d4e628dd2b194bd884d4943225240218",
      "c83b16fa0556459ebbf884a524229a47",
      "139eac322f9f46b08fced4bd9f220a30",
      "a7dab729cb0843b19349eb4261357203",
      "89807a7d455b4f73bf5c7672d6f7eb33",
      "53118f83c4704c3a9fb1b87defbd152c",
      "fdf14609a6c8400c96e732575fb61e88",
      "b56b6d34312c4890823da001dd943f3c",
      "90d5c5e61b8c41f5821376b0f42ff086",
      "75f950abd5cc426c99c4f9a33345fc11",
      "574c29d5a0e54448a7f686ee28d64c1f",
      "af5e6e5a2df240ff953e125e13f492ce",
      "3866d8a7eac2448db6ec8b8fd6601d14",
      "127338c85dc945768d2efc4cae337708",
      "2089662f8c9a4d3791e1b77cda152a4c",
      "fcf14b1dd48646df8571f2ada7e67612",
      "7f43fe08dac64784a502561659618c2f",
      "85bfd011522a4b6d8fdf8f2fb709cc0d",
      "5cf7270cd9a943808d6acc3b6bf82fee",
      "3a0b9136f4344454821b56b63c522fdd",
      "d039e3b26c404f4f94986dbc9cc29a01",
      "b9aa1aa9a71f4c54850ce23ec02d81e3",
      "2eaa47dd120d42e39c4117b03bb1fcc3",
      "16ae063142f34033b340b80586b69a54",
      "4828029c3aca4365af178721667fb016",
      "d73526b8bd55431b995172286b16cd04",
      "c453789950214364b2583cd25f8725b7",
      "aab83800d28a4fe697d64e1680daf504",
      "a5b44d2f14924ab6a600f324743ce866",
      "ceb8c78d596c498ea92a704636ebcc26",
      "8f2e0842ac4045a4b57cfdfdfbe30e90",
      "0d09b625d8a94c3cb9cbd106edd11613",
      "e42bfb2a134549988c055c17b13c2416",
      "7a5143bf26484b6e8357cd416854c381",
      "09254ec64c864274b09a3ad757a75351",
      "254d2d6fedca4231bbc0a03a14602845",
      "4f28463dd9234aa3909e9d85eec7c46f",
      "a1b80524e70f4c9792309acbf2c31233",
      "dfcf73856c794462962ecfca13d734a8",
      "2899da772a774a249171144910a57abe",
      "a4097b59e6514d838b607fd954278973",
      "e50ca76503434f83afe89e7e39ca98f3",
      "28e9d749f15f43c39f7e102d507000af",
      "73900e3797534e049082ca6df8557582",
      "2db4e9ccfcb24f2db819022d5fb83597",
      "828f1ff5b0d24d9db19f02d8585e89df",
      "79f83d057e9d43ed90397b7d628a753c",
      "e0461d9f834746ecb96e88b17433156e",
      "18086ffab360422f8f3835b2b91a9a9e",
      "5d58d598966d4a9ca1179349d731d16c",
      "ad413e63b8b543a3aecbaa319b37c4ae",
      "a10a08dcd91643c7bef9a746301961e4",
      "f2c7b53dc2ac484c8765a4ff802ac585",
      "f076605731234ab7a1a91f48c95d9350",
      "e73136c5e646411fbe792d5a7da09853",
      "e97937da5bfd4028a5d6a41d599b7427",
      "a2c18316551f46b7ad2d0003e79410f6",
      "a4af6b1d5e634af4bc4c7d31ebefbd20",
      "232c2ee405a34a01af82320be153790e",
      "9fd3c644a66b4c1a86439e1c2edfda15",
      "a3b89a3e4c384d9db121da9716279daa",
      "b818945bab154f6b8eac02b26f55e8e6",
      "1040253914414f80bd55c19f862d67b1",
      "c20812c81ab245dc924b27b590af0ef9",
      "72fca04ae66e4b5cb649ec00038103f2",
      "7550d152e48a4cfb8e69db19f819d13b",
      "a5cc55fabf4144be82d145b10dff1b57",
      "4c6d7dd3b6724ab58776672be77b8684",
      "0409e425476d4711b52b4b05f0d1e44a",
      "31b9329dd7bd4f8e84e34a135d7e49fd",
      "045b73f2d1314542902a6656fdf8ea8e",
      "e07817983290417ea7c660b82038f8fe",
      "e2fcf82d06b2407f87d2240e99ea4158",
      "32c7c6ddddf14acd82400b274b616110",
      "4175b0b66ab14576a92e2867e13bb135",
      "070e8e72b0a9488c8785a0e7584845ea",
      "253f1e14d5e34280a5202be54bc3914a",
      "b04bf20237a04fc29cdaceec34ddae6e",
      "17a7049aac9d47bcb4dcddb82ae2528c",
      "fca13ae27c52409892617155727da7e4",
      "c383c1f2c3c449a38b341a321876cabb",
      "4e0d826032534541a061f168ebdb9620",
      "a7e4f7ee8bbf45c1b5a235e9e3b45ee5",
      "cfc9d59856b04c6ab55baa8b96565ae1",
      "3dd865efa66f4291af5515e4880b55bf",
      "45e5735c6332469787e8be561c1a397a",
      "659b2d4d4d9c49ec82b9bb1e5f3098f8",
      "6914f9fdd3d14f2fa3abb2468dbc9ccd",
      "29e1f5e294ff47b2a1b456b76adffa47",
      "925ea926668e4ceeb577a2893db47971",
      "90eca9cc666e428d999799b44923104f",
      "0b801063d2f34d71b6f0c632c8aef12e",
      "4d6e91bbd467427a80be749224ccaf22",
      "ab28d182f570459fb36879d66aaa50f9",
      "1017fe885a264067bb8b9a50176aaf08",
      "97858d9fd2b147e58ddaea7c60757b8d",
      "61c936b19f3d4ec982d973dd05ac0115",
      "66ea012461bb4fc78612c6d44cc85a93",
      "42e56364c4274eb98967900747b2cd2b",
      "57f9b1b52336450fba215f06e62e1058",
      "1c79c8c269db474990b4e8310b833391",
      "b07bd97c28724f0eba68271df490f8c4",
      "8ef2512c09334b2e9b3860b7a2497c27",
      "e29c412840de4421869cb8048c6fda85",
      "03c6ee66e0cf49d7b9d1e7f35387cde4",
      "aef1caccc77c44fbb513393a5f9cc15d",
      "68952c537d724b93860a6c7868653f02",
      "3576a421e68e4885a10509dbcc21ee9a",
      "96f556bbe1524dd8a3d95aac42813bbd",
      "1c3beca8da6148eb9bd40ec1c20b681d",
      "5288682e531945f484fd6035e92599b6",
      "fbd77a05fadb46c3a24384071f3d58ce",
      "87e8839e31fa4c7e885cd849c2fea6f0",
      "ed31a2e2a86c40a48a9c195c90f8460f",
      "becac66aab1c4a9b831ab67d61cf9228",
      "ecfb938c7d07429185c387eb0d1a97a2",
      "b53f551786184158837eeabf52a3dfe9",
      "2bb78d6e54774ca6b08605b4609758ce",
      "146e38874c744e568ad30ccbe63462d2",
      "b1a2bf45b4444733a9ef85be8e49a1cb",
      "068ea8b34f2a4df498bb597fabb2f66f",
      "68485bc3769649c69d60f746ff1ccbe2",
      "76047ea9d36b4ce38375a0218dcbadff",
      "0c2200299176431bbdb8a4811c3cc99d",
      "e28be0ee4de04b74af5fe612224d6e23",
      "dabe4c22a27e4dbbb955ceb64b32ec84",
      "5a94b313ac81401ba8711910e14cf865",
      "002c40a3a81842fcada8c2a813fa2137",
      "ee521db3285e4e71ae977e4de9accf28",
      "f48ddb039c374ff38cb3b79ba48881ab",
      "0b2525a140db40bbaa537ecdbdc24ff1",
      "bade1fbb1e364591932e71cfa9134b8b",
      "68f763dd23f34ec4a2d4c233abdf01c4",
      "271e61e33b7849109483d0c38575ee34",
      "feafac202fb44ccc86029213b2a10fc0",
      "34fac9173c104c9d997f1c3c52a0893d",
      "2269b09fef6145459f31fcbd692923fb",
      "1a62a77ab2cd42da83a830976da0857c",
      "859650159da34b3fa05f10c339806b57",
      "8c865f23331848e4adabe99007c63267",
      "966521a2f0b44022b70977dfd7236391",
      "7f3de9cff2524b70bd49f09e3a6b2ce3",
      "be0bd2249f044077921317a3303e1f9f",
      "7ecaa97034394550b4f9829c0286ab90",
      "379a785c31d24eed9317bd433935729a",
      "7e6fac46530a4ba799648cc9134ba834",
      "6d9c8968f11747688df7798b7a2973ae",
      "06739a7b03974d57afad0c422f58f8db",
      "daf04d7b89094ee79537c14335651273",
      "70e567f6f39f48fba3f541a26f1c61a4",
      "f95e76307fb54e04890724ca1a6a4891",
      "25c728ce7a1242b48dd152bfd28d875d",
      "25dd1a0cf47646ccbe95208d49d0b35f",
      "e2955148969d46c18c879ad35e922c73",
      "fa1ac11a986e42f5a43b691f77df3875",
      "f882283e8ef74f77aa864c8f4741cd23",
      "66452f0d47a24cadaf311d02962d8d7a",
      "3aaa105e3ce8478889a232cf7afd36e0",
      "a2581a845cfc44338102dcedadaba70c",
      "c4bff1e0b35e43d69b99da6e83be6918",
      "4af1a01145ae4d9f8253516c565082ee",
      "c5141a0d15e441aba090f1fe9e6da400",
      "28fbeb0e73ae4f2dbb8831162aa0de2b"
     ]
    },
    "executionInfo": {
     "elapsed": 1663466,
     "status": "ok",
     "timestamp": 1752071356640,
     "user": {
      "displayName": "Dagemawi Negash",
      "userId": "15489963942441824172"
     },
     "user_tz": -180
    },
    "id": "LQ1ctyDWlgso",
    "outputId": "19869573-c9be-4c10-ccd5-bf542be3c344"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 64\n",
    "n_epochs = 30\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "context_dim = 128\n",
    "emb_dim = 128\n",
    "model = UNet(img_ch=1, base_ch=64, emb_dim=emb_dim, context_dim=context_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "null_text = [\"\"] * batch_size\n",
    "null_context = get_text_embedding(null_text, device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, texts, _ in tqdm(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        t = torch.randint(0, T, (imgs.size(0),), device=device)\n",
    "        noise = torch.randn_like(imgs)\n",
    "        alpha_cumprod_t = alphas_cumprod.to(device)[t].reshape(-1, 1, 1, 1)\n",
    "        noisy_imgs = torch.sqrt(alpha_cumprod_t) * imgs + torch.sqrt(1 - alpha_cumprod_t) * noise\n",
    "        # 10% of the time, use null context (unconditional)\n",
    "        if random.random() < 0.1:\n",
    "            context = null_context[:imgs.size(0)]\n",
    "        else:\n",
    "            context = get_text_embedding(list(texts), device)\n",
    "\n",
    "        t_emb = get_timestep_embedding(t, emb_dim)\n",
    "        t_emb = t_emb.to(device)\n",
    "\n",
    "        pred_noise = model(noisy_imgs, t_emb, context)\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} done. Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOvF/9qvzfBViDQs8tiQzzn",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1K7s_hZLyfjba5as2RyO4-I1Z9GvMaTNd",
     "timestamp": 1752072533035
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
